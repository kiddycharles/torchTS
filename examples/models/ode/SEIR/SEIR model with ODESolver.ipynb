{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SEIR Epidemiologic Model with TorchTS ODE Solver\n",
    "\n",
    "This example solves a compartmental model used in epidemiology, known as \n",
    "[SEIR](https://en.wikipedia.org/wiki/Compartmental_models_in_epidemiology#The_SEIR_model) \n",
    "model, using the TorchTS ODE Solver.\n",
    "\n",
    "The ODE (ordinary differential equation) system, in generic form, is\n",
    "\n",
    "\\begin{equation*}\n",
    "    \\frac{d \\mathbf{A}}{d t} = \\mathbf{F}(a_n)\n",
    "\\end{equation*}\n",
    "\n",
    "or in uncollapsed form\n",
    "\n",
    "\\begin{align*}\n",
    "\\frac{d a_1}{d t} =& f_1(a_1, a_2, \\dots a_n) \\\\\n",
    "\\frac{d a_2}{d t} =& f_2(a_1, a_2, \\dots a_n) \\\\\n",
    "\\vdots \\\\\n",
    "\\frac{d a_n}{d t} =& f_n(a_1, a_2, \\dots a_n) \\\\\n",
    "\\end{align*}\n",
    "\n",
    "In the case of the SEIR model, the ODEs are:\n",
    "<br>\n",
    "\\begin{align}\n",
    "\\frac{d S_t}{dt} &= - \\frac{\\beta_t I_t S_t}{N}, \\\\\n",
    "\\frac{d E_t}{dt} &= \\frac{\\beta_t I_t S_t}{N} - \\sigma_t E_t \\\\\n",
    "\\frac{d I_t}{dt} &= \\sigma_t E_t - \\gamma_t I_t \\\\\n",
    "\\frac{d R_t}{dt} &= \\gamma_t I_t\n",
    "\\end{align}\n",
    "\n",
    "Here, the the compartment $S$ (susceptible population) represents the first variable $a_1$, and $f_1$ is denoted by the right-hand-side of the top equation.\n",
    "The coefficients $\\beta$, $\\sigma$ and $\\gamma$ (either constant or time-dependent, still to be implemented) are optimized using PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to solve various different systems of ODEs, the following quantities must be somehow parameterized and passed to the solver:\n",
    "- The equations $f_n$. \n",
    "- The coefficients (and a flag denoting whether they are time-dependent)\n",
    "- The data used to train the model. \n",
    "- An optional output modifier which takes the numerical solution and brings it into a shape consistent with the training data such that the loss can be calculated, as explained below.\n",
    "- Other user-controllable parameters including the temporal discretization (time step),\n",
    "optimizer, scheduler learning rate and loss function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specification of the variables, parameters and functions\n",
    "\n",
    "Variables, ODEs and initial values for coefficients are passed to the function during initialization:\n",
    "\n",
    "    ODESolver(inivals, cfuncs, inicoeffs, dt, time-dependent=False, \n",
    "        solver='Euler', outvar=None)\n",
    "\n",
    "##### Variables\n",
    "For working with the solver it's easier and more intuitive to assign actual variable names to each quantity.\n",
    "They are provided as the keys in the dictionary passed to \n",
    "the positional argument `inivals`.   The values of the dictionary provide the initial values assigned to each quantity.\n",
    "For the SEIR model, one could use, for example:\n",
    "\n",
    "    inivals = {\"S\": 0.95, \"E\": 0.,\"I\" 0.05 : ,\"R\": 0}\n",
    "    \n",
    "(Here, the population in each compartments is normalized by the total population size).\n",
    "\n",
    "##### Functions\n",
    "\n",
    "A function specifying the right-hand term in each of the system of ODE's is passed to the solver as a dictionary in the\n",
    "positional argument `cfuncs`.  The equation pertaining to each variable is stored under the key representing the respective variable.\n",
    "Each function receives two positional arguments, `cvars` and `coeffs`.  These will be dictionaries containing the \n",
    "system's current variables and coefficients.  As an example, the function describing the ODE for quantity $S$ would be defined as:\n",
    "\n",
    "    def fS(cvar, coeffs):\n",
    "        return (-coeffs[\"beta\"] * cvar[\"I\"] * cvar[\"S\"])\n",
    "\n",
    "##### Inicoeffs\n",
    "\n",
    "Initial values for the coefficients are provided in the dictionary inicoeffs.  Each coefficient must be present,\n",
    "and the keys in the dictionary passed to the solver must represent the names of the coefficients that will be optimized through data.\n",
    "\n",
    "In the SEIR example, one could use\n",
    "    \n",
    "    inicoeffs={\"beta\": 0.50, \"gamma\": 0.20, \"sigma\": 0.20}\n",
    "\n",
    "#####  Output quantities (and time skip, still ToDo):\n",
    "\n",
    "By default, the network returns a time-dependent value for every variable and every discrete time step resolved \n",
    "during numerical integration.  Depending on the model and data, a training value may not be available for quantity.\n",
    "For example, only data on the currently infected and susceptible population was typically be available during the Covid-19 pandemic, but not on the exposed population.\n",
    "(Alternatively, one might only have data on cumulative reported cases (`cumsum(I)`), not currently infectious cases.\n",
    "Handling such cases will require functionaly that is not yet implemented.)\n",
    "\n",
    "The keyword variable `outvar` designates the names of the output quantities that are present in the data and used \n",
    "for computation of the loss.  In addition, it indicates the order in which they are present in the training dataset\n",
    "(format described below).\n",
    "By default, `outvar` is the same as `variables`.  In the case of the compartmental model, one would use\n",
    "`outvar = [\"S\",\"I\",\"R\"]`, as no data on the exposed population $E$ is available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the network\n",
    "\n",
    "The solver is trained using \n",
    "\n",
    "    ODESolver.fit(train_data,  num_epochs=100,  lr=0.001, optimizer= None, \n",
    "        scheduler = None, loss_fun=torch.nn.MSELoss()):\n",
    "\n",
    "The PyTorch tensor `train_data` is assumed to be of the shape `(nt,nvar)`, where `nt` is the number of time steps used for training and `nvar` is the number of output variables (consistent with `len(outvar)`).  The sampling interval of the data is expected to be the same as the timestep `dt` passed to the solver during initialization.\n",
    "\n",
    "By default, the value `None` is passed for the optimizer and scheduler, \n",
    "and the network uses \n",
    "\n",
    "    optimizer = torch.optim.Adam(self.coeffs.values(), 0.001)        \n",
    "    scheduler=torch.optim.lr_scheduler.StepLR(optimizer, step_size= 1, gamma=0.95)\n",
    "  \n",
    "To learning rate can be changed using the keyword argument `lr`.  If a custom optimizer is provided,\n",
    "the optimizer's coded learning rate is used.  A warning is issued if the user tries to set both.\n",
    "\n",
    "### Predicting\n",
    "\n",
    "Predictions are made using \n",
    "\n",
    "    ODESolver.predict(nt)\n",
    "   \n",
    "Where `nt` represents the total number of time steps in the prediction (starting from the same origin time as used in the training data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from scipy.integrate import odeint\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"4\"\n",
    "#device = torch.device(\"cpu\")\n",
    "print(device)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If torchts is properly installed, the module should be in the path already.  This code adds the\n",
    "module `ode` to the current path assuming the example is called directly from the repository's tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "source": [
    "try:\n",
    "    from torchts.nn.models import ode\n",
    "except ModuleNotFoundError:\n",
    "    import sys\n",
    "    sys.path.append(\"../../..\")\n",
    "    from torchts.nn.models import ode"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining all the functions.  Here, the coefficient $\\beta$ is assumed to be normalized by the total population $N$ already.  Population sizes are assumed normalized by the total population as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "source": [
    "def fS(cvar, coeffs):\n",
    "    return -coeffs[\"beta\"] * cvar[\"I\"] * cvar[\"S\"]\n",
    "\n",
    "def fE(cvar, coeffs):\n",
    "    return coeffs[\"beta\"] * cvar[\"I\"] * cvar[\"S\"] - coeffs[\"sigma\"] * cvar[\"E\"]\n",
    "\n",
    "def fI(cvar, coeffs):\n",
    "    return coeffs[\"sigma\"] * cvar[\"E\"] - coeffs[\"gamma\"] * cvar[\"I\"]\n",
    "\n",
    "def fR(cvar, coeffs):\n",
    "    return coeffs[\"gamma\"] * cvar[\"I\"]\n",
    "\n",
    "cfuncs={\"S\": fS, \"E\": fE, \"I\": fI, \"R\": fR}"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training and validation data is loaded from the provided `PyTorch` file and normalized:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "source": [
    "SIR=torch.load(\"SIR_data_SD_county.pt\")\n",
    "\n",
    "npop=SIR[0,0].numpy().copy()\n",
    "print(\"Total population: %d\" % npop)\n",
    "SIR[:,:] = SIR[:,:] / torch.tensor(npop)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing the training data.  Here, just a short excerpt of the full time range is used.\n",
    "Time-dependent coefficients are needed to fit longer time windows.  This is not yet implemented in the ODE library, but in the specific solver for the SEIR model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "source": [
    "training_data=SIR.float()[350:380,:]\n",
    "nt_train=training_data.shape[0]\n",
    "test_data=SIR.float()[350:410,:]\n",
    "nt=test_data.shape[0]\n",
    "print(\"nt=%d\" % nt)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "source": [
    "#The values at the beginning of the observation are taken as initial values\n",
    "inivals={}\n",
    "for n,var in enumerate([\"S\",\"I\",\"R\"]):\n",
    "    inivals[var] = training_data[0,n]\n",
    "\n",
    "#The fraction of the initial exposed population is assumed twice the infected fraction\n",
    "inivals[\"E\"] = inivals[\"I\"] * 2.\n",
    "print(inivals)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "source": [
    "inicoeffs={\"beta\": 0.50, \"gamma\": 0.20, \"sigma\": 0.20}"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function is initialized using the initial values, initial coefficients and functions (right-hand-sides of ODEs) provided above.  Also specified are the output variables given in the training data, in the order in which they are present:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "source": [
    "# myopt=torch.optim.SGD(seir.coeffs.values(), 0.005)\n",
    "seir=ode.ODESolver(\n",
    "    cfuncs, \n",
    "    inivals, \n",
    "    inicoeffs, \n",
    "    dt=1, \n",
    "    outvar=[\"S\",\"I\",\"R\"], \n",
    "    optimizer=torch.optim.SGD,\n",
    "    optimizer_args={\"lr\":0.005}\n",
    "    )"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "source": [
    "seir.fit(training_data, training_data, max_epochs=1000)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values of the optimized coefficients can be retrieved like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "source": [
    "seir.get_coeffs()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training using custom optimizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "source": [
    "#myopt=torch.optim.SGD(seir.coeffs.values(), 0.005)\n",
    "#seir.fit(training_data, optimizer=myopt)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "source": [
    "y_predict=seir.predict(nt)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "source": [
    "fig,ax=plt.subplots()\n",
    "clr=[\"b\",\"r\",\"g\"]\n",
    "\n",
    "for n,var in enumerate(seir.outvar):\n",
    "    ax.plot(test_data[:nt,n], label=\"%s (obs)\" % var, color=clr[n])\n",
    "    ax.plot(y_predict.detach()[:,n], label=\"%s (sim)\" % var, \n",
    "            linestyle=\"dashed\", color=clr[n])\n",
    "    \n",
    "    ax.set_ylim(0, 1.00)\n",
    "    ax.vlines(nt_train, 0, 1.00, color='k', linestyle='dotted')\n",
    "    ax.legend(loc='center left')\n",
    "    ax.set_xlabel(\"Time (days)\")\n",
    "    ax.set_ylabel(\"Population Fraction\")\n",
    "\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Figure above shows the observed (solid) against the simulated (dashed) compartment fractions.  The vertical, dotted line marks the end of the training window; values beyond 30 days are predicted from the minimum misfit model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
