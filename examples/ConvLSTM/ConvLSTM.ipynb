{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Introduction\n",
    "\n",
    "It is common nowadays to find data in the form of a sequence of images. The most typical example is video at social networks such as YouTube, Facebook and Instagram. Other classical examples are video calls, movies and trailers, satellites images and security cameras. \n",
    "We will show you how to code a ConvLSTM model for frame prediction using MovingMNIST dataset."
   ],
   "id": "7a201cec198126a2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Libraries",
   "id": "ff047564c1ca3bb3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T09:56:58.323230Z",
     "start_time": "2024-05-16T09:56:54.738149Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# import libraries\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from lightning import Trainer\n",
    "from multiprocessing import Process\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "from torchts.utils.start_tensorboard import run_tensorboard\n",
    "from torchts.nn.models.ConvLSTM import Seq2SeqConvLSTM, MovingMNISTConvLSTM"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Dataloader\n",
    "The dataloader script f"
   ],
   "id": "36a92e9780f40cc6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T09:56:58.332125Z",
     "start_time": "2024-05-16T09:56:58.324418Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# from: https://github.com/edenton/svg/blob/master/data/moving_mnist.py\n",
    "\n",
    "class MovingMNIST(object):\n",
    "    \"\"\"Data Handler that creates Bouncing MNIST dataset on the fly.\"\"\"\n",
    "\n",
    "    def __init__(self, train, data_root, seq_len=20, num_digits=2, image_size=64, deterministic=True):\n",
    "        path = data_root\n",
    "        self.seq_len = seq_len\n",
    "        self.num_digits = num_digits\n",
    "        self.image_size = image_size\n",
    "        self.step_length = 0.1\n",
    "        self.digit_size = 32\n",
    "        self.deterministic = deterministic\n",
    "        self.seed_is_set = False  # multi thread loading\n",
    "        self.channels = 1\n",
    "\n",
    "        self.data = datasets.MNIST(\n",
    "            path,\n",
    "            train=train,\n",
    "            download=False,\n",
    "            transform=transforms.Compose(\n",
    "                [transforms.Resize(self.digit_size),\n",
    "                 transforms.ToTensor()]))\n",
    "\n",
    "        self.N = len(self.data)\n",
    "\n",
    "    def set_seed(self, seed):\n",
    "        if not self.seed_is_set:\n",
    "            self.seed_is_set = True\n",
    "            np.random.seed(seed)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.N\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        self.set_seed(index)\n",
    "        image_size = self.image_size\n",
    "        digit_size = self.digit_size\n",
    "        x = np.zeros((self.seq_len,\n",
    "                      image_size,\n",
    "                      image_size,\n",
    "                      self.channels),\n",
    "                     dtype=np.float32)\n",
    "        for n in range(self.num_digits):\n",
    "            idx = np.random.randint(self.N)\n",
    "            digit, _ = self.data[idx]\n",
    "\n",
    "            sx = np.random.randint(image_size - digit_size)\n",
    "            sy = np.random.randint(image_size - digit_size)\n",
    "            dx = np.random.randint(-4, 5)\n",
    "            dy = np.random.randint(-4, 5)\n",
    "            for t in range(self.seq_len):\n",
    "                if sy < 0:\n",
    "                    sy = 0\n",
    "                    if self.deterministic:\n",
    "                        dy = -dy\n",
    "                    else:\n",
    "                        dy = np.random.randint(1, 5)\n",
    "                        dx = np.random.randint(-4, 5)\n",
    "                elif sy >= image_size - 32:\n",
    "                    sy = image_size - 32 - 1\n",
    "                    if self.deterministic:\n",
    "                        dy = -dy\n",
    "                    else:\n",
    "                        dy = np.random.randint(-4, 0)\n",
    "                        dx = np.random.randint(-4, 5)\n",
    "\n",
    "                if sx < 0:\n",
    "                    sx = 0\n",
    "                    if self.deterministic:\n",
    "                        dx = -dx\n",
    "                    else:\n",
    "                        dx = np.random.randint(1, 5)\n",
    "                        dy = np.random.randint(-4, 5)\n",
    "                elif sx >= image_size - 32:\n",
    "                    sx = image_size - 32 - 1\n",
    "                    if self.deterministic:\n",
    "                        dx = -dx\n",
    "                    else:\n",
    "                        dx = np.random.randint(-4, 0)\n",
    "                        dy = np.random.randint(-4, 5)\n",
    "\n",
    "                x[t, sy:sy + 32, sx:sx + 32, 0] += digit.numpy().squeeze()\n",
    "                sy += dy\n",
    "                sx += dx\n",
    "\n",
    "        x[x > 1] = 1.\n",
    "        return x"
   ],
   "id": "8c4b3e5ad1978cf3",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T09:56:58.336289Z",
     "start_time": "2024-05-16T09:56:58.333010Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Parameters:\n",
    "    def __init__(self, path=None, lr=1e-4, beta_1=0.9, beta_2=0.98, batch_size=12,\n",
    "                 epochs=300, use_amp=False, n_gpus=1, n_hidden_dim=64, n_layers=1,\n",
    "                 n_steps_ahead=10, n_steps_past=10):\n",
    "        self.path = path if path else os.getcwd() + '/data'\n",
    "        self.lr = lr\n",
    "        self.beta_1 = beta_1\n",
    "        self.beta_2 = beta_2\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.use_amp = use_amp\n",
    "        self.n_gpus = n_gpus\n",
    "        self.n_hidden_dim = n_hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.n_steps_ahead = n_steps_ahead\n",
    "        self.n_steps_past = n_steps_past\n",
    "        \n",
    "# Example usage:\n",
    "opt = Parameters()"
   ],
   "id": "62a38da7d85d8659",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T09:56:58.340487Z",
     "start_time": "2024-05-16T09:56:58.338185Z"
    }
   },
   "cell_type": "code",
   "source": "print(opt.path)",
   "id": "fbc2b811cbddb92c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/kiddycharles/torchTS/examples/ConvLSTM/data\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T09:56:58.408434Z",
     "start_time": "2024-05-16T09:56:58.341257Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "train_data = MovingMNIST(train=True,\n",
    "                         data_root=opt.path,\n",
    "                         seq_len=opt.n_steps_past + opt.n_steps_ahead,\n",
    "                         image_size=64,\n",
    "                         deterministic=True,\n",
    "                         num_digits=2)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_data,\n",
    "                                           batch_size=opt.batch_size,\n",
    "                                           shuffle=True)\n",
    "\n",
    "\n",
    "test_data = MovingMNIST(train=False,\n",
    "                        data_root=opt.path,\n",
    "                        seq_len=opt.n_steps_past + opt.n_steps_ahead,\n",
    "                        image_size=64,\n",
    "                        deterministic=True,\n",
    "                        num_digits=2)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_data,\n",
    "                                          batch_size=opt.batch_size,\n",
    "                                          shuffle=True)\n"
   ],
   "id": "b32895c38537d1c2",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T09:56:58.417170Z",
     "start_time": "2024-05-16T09:56:58.409252Z"
    }
   },
   "cell_type": "code",
   "source": [
    "conv_lstm_model = Seq2SeqConvLSTM(nf=opt.n_hidden_dim, in_channel=1)\n",
    "model = MovingMNISTConvLSTM(opt=opt, model=conv_lstm_model)"
   ],
   "id": "78e53205ad505111",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-05-16T09:56:58.418166Z"
    }
   },
   "cell_type": "code",
   "source": [
    "trainer = Trainer(accelerator='mps', devices=1, max_epochs=opt.epochs)\n",
    "trainer.fit(model, train_dataloaders=train_loader)"
   ],
   "id": "b9c56752063a815f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "\n",
      "  | Name      | Type            | Params\n",
      "----------------------------------------------\n",
      "0 | model     | Seq2SeqConvLSTM | 1.0 M \n",
      "1 | criterion | MSELoss         | 0     \n",
      "----------------------------------------------\n",
      "1.0 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.0 M     Total params\n",
      "4.144     Total estimated model params size (MB)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ced6a12b7db34b72acbc3947a064636c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "1b66cb869a77198c",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
